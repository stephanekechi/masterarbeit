{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping fact checking article on Donald Trump statemnts from Politifact article\n",
    "import requests \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datefinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_record(records, file_path):\n",
    "    #df.to_csv('Dataset/true_facts.csv', index=False, encoding='utf-8')\n",
    "    records.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_news():\n",
    "    false_request = requests.get('https://www.politifact.com/factchecks/list/?page=1&ruling=false')\n",
    "    #print(false_request.text)\n",
    "    soup = BeautifulSoup(false_request.text, 'html.parser')\n",
    "    results = soup.find_all('article', attrs={'class':'m-statement m-statement--is-medium m-statement--false'})\n",
    "    records = []  \n",
    "    for result in results:\n",
    "        subject_class =  result.find('div', attrs={'class':'m-statement__meta'})\n",
    "        subject = subject_class.find('a', attrs={}).text\n",
    "        text_class = result.find('div', attrs={'class': 'm-statement__quote'})\n",
    "        text =  text_class.find('a', attrs={}).text\n",
    "        title = ''\n",
    "        date_text = result.find('div', attrs={'class': 'm-statement__desc'}).text\n",
    "        print(date_text)\n",
    "        date = retrieve_date(date_text)\n",
    "        #url =  result.find('a')['href']\n",
    "\n",
    "        records.append((title, text, subject, date))\n",
    "\n",
    "    #df = pd.DataFrame(records, columns=['Date', 'Lie','Fact', 'Url'])\n",
    "    #print(records)\n",
    "    df = pd.DataFrame(records, columns=['title', 'text', 'subject', 'date'])\n",
    "    #print(df.date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_date(text):\n",
    "    dates = datefinder.find_dates(text)\n",
    "    date = None\n",
    "    \n",
    "    for elt_date in dates:\n",
    "        date = elt_date\n",
    "        print(date)\n",
    "        \n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_news():\n",
    "    true_request = requests.get('https://www.politifact.com/factchecks/list/?page=1&ruling=true')\n",
    "    #print(false_request.text)\n",
    "    soup = BeautifulSoup(true_request.text, 'html.parser')\n",
    "    results = soup.find_all('article', attrs={'class':'m-statement m-statement--is-medium m-statement--true'})\n",
    "    records = []  \n",
    "    for result in results:\n",
    "        subject_class =  result.find('div', attrs={'class':'m-statement__meta'})\n",
    "        subject = subject_class.find('a', attrs={}).text\n",
    "        text_class = result.find('div', attrs={'class': 'm-statement__quote'})\n",
    "        text =  text_class.find('a', attrs={}).text\n",
    "        title = ''\n",
    "        date_text = result.find('div', attrs={'class': 'm-statement__desc'}).text\n",
    "        date = retrieve_date(date_text)\n",
    "        #url =  result.find('a')['href']\n",
    "\n",
    "        records.append((title, text, subject, date))\n",
    "\n",
    "    #df = pd.DataFrame(records, columns=['Date', 'Lie','Fact', 'Url'])\n",
    "    #print(records)\n",
    "    df = pd.DataFrame(records, columns=['title', 'text', 'subject', 'date'])\n",
    "    #print(df.date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stated on February 12, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-12 00:00:00\n",
      "\n",
      "stated on February 23, 2021 in an online post:\n",
      "\n",
      "2021-02-23 00:00:00\n",
      "\n",
      "stated on February 16, 2021 in a Facebook post:\n",
      " \n",
      "2021-02-16 00:00:00\n",
      "\n",
      "stated on February 23, 2021 in a tweet:\n",
      "\n",
      "2021-02-23 00:00:00\n",
      "\n",
      "stated on February 22, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-22 00:00:00\n",
      "\n",
      "stated on February 23, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-23 00:00:00\n",
      "\n",
      "stated on February 19, 2021 in a TV segment:\n",
      "\n",
      "2021-02-19 00:00:00\n",
      "\n",
      "stated on February 21, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-21 00:00:00\n",
      "\n",
      "stated on February 19, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-19 00:00:00\n",
      "\n",
      "stated on February 21, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-21 00:00:00\n",
      "\n",
      "stated on February 22, 2021 in a TV segment:\n",
      "\n",
      "2021-02-22 00:00:00\n",
      "\n",
      "stated on February 16, 2021 in a Tweet:\n",
      "\n",
      "2021-02-16 00:00:00\n",
      "\n",
      "stated on February 17, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-17 00:00:00\n",
      "\n",
      "stated on February 21, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-21 00:00:00\n",
      "\n",
      "stated on February 8, 2021 in a blog item posted on Facebook:\n",
      "\n",
      "2021-02-08 00:00:00\n",
      "\n",
      "stated on February 18, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-18 00:00:00\n",
      "\n",
      "stated on February 15, 2021 in a post on Facebook:\n",
      "\n",
      "2021-02-15 00:00:00\n",
      "\n",
      "stated on February 13, 2021 in a text post:\n",
      "\n",
      "2021-02-13 00:00:00\n",
      "\n",
      "stated on February 19, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-19 00:00:00\n",
      "\n",
      "stated on February 17, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-17 00:00:00\n",
      "\n",
      "stated on February 16, 2021 in an interview:\n",
      "\n",
      "2021-02-16 00:00:00\n",
      "\n",
      "stated on February 17, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-17 00:00:00\n",
      "\n",
      "stated on January 31, 2021 in TV interview:\n",
      "\n",
      "2021-01-31 00:00:00\n",
      "\n",
      "stated on February 15, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-15 00:00:00\n",
      "\n",
      "stated on February 16, 2021 in remarks at a CNN town hall:\n",
      "\n",
      "2021-02-16 00:00:00\n",
      "\n",
      "stated on February 13, 2021 in a billboard:\n",
      "\n",
      "2021-02-13 00:00:00\n",
      "\n",
      "stated on February 16, 2021 in a radio interview:\n",
      "\n",
      "2021-02-16 00:00:00\n",
      "\n",
      "stated on February 1, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-01 00:00:00\n",
      "\n",
      "stated on February 11, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-11 00:00:00\n",
      "\n",
      "stated on February 8, 2021 in a Facebook post:\n",
      "\n",
      "2021-02-08 00:00:00\n"
     ]
    }
   ],
   "source": [
    "result_fake = get_false_news()\n",
    "#result_fake.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-22 00:00:00\n",
      "2021-02-09 00:00:00\n",
      "2021-02-16 00:00:00\n",
      "2021-02-16 00:00:00\n",
      "2021-02-05 00:00:00\n",
      "2021-01-14 00:00:00\n",
      "2021-01-26 00:00:00\n",
      "2021-01-18 00:00:00\n",
      "2021-01-22 00:00:00\n",
      "2021-01-12 00:00:00\n",
      "2021-01-19 00:00:00\n",
      "2021-01-13 00:00:00\n",
      "2021-01-10 00:00:00\n",
      "2021-01-09 00:00:00\n",
      "2021-01-13 00:00:00\n",
      "2021-01-08 00:00:00\n",
      "2021-01-07 00:00:00\n",
      "2021-01-06 00:00:00\n",
      "2021-01-07 00:00:00\n",
      "2021-01-03 00:00:00\n",
      "2020-12-27 00:00:00\n",
      "2020-11-09 00:00:00\n",
      "2020-12-07 00:00:00\n",
      "2020-12-11 00:00:00\n",
      "2020-11-17 00:00:00\n",
      "2020-12-01 00:00:00\n",
      "2020-12-03 00:00:00\n",
      "2020-11-18 00:00:00\n",
      "2020-11-15 00:00:00\n",
      "2020-10-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "result_true = get_true_news()\n",
    "#result_true.date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
